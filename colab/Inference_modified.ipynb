{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtlIRiNXWlQ0"
      },
      "source": [
        "# Modified Waste identification with instance segmentation in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HhMR363skKaY"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue7zrphcIFGi",
        "outputId": "ff283ee8-e8ca-4c1e-e3fc-2170027e07ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ELUFMVDDAopS"
      },
      "outputs": [],
      "source": [
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import logging\n",
        "import pandas as pd\n",
        "\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qhk_NujKO0mb"
      },
      "outputs": [],
      "source": [
        "# Clone the tensorflow models repository.\n",
        "!git clone --depth 1 https://github.com/tensorflow/models 2>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fBAdlmHKO3AV"
      },
      "outputs": [],
      "source": [
        "# Download the script to pull instance segmentation model weights from the TF Model Garden repo.\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/\"\n",
        "    \"tensorflow/models/master/\"\n",
        "    \"official/projects/waste_identification_ml/\"\n",
        "    \"model_inference/download_and_unzip_models.py\"\n",
        ")\n",
        "\n",
        "!wget -q {url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o1dYyG55BtWb"
      },
      "outputs": [],
      "source": [
        "sys.path.append('models/research/')\n",
        "from object_detection.utils import visualization_utils as viz_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cbcEDJHAB65J"
      },
      "outputs": [],
      "source": [
        "sys.path.append('models/official/projects/waste_identification_ml/model_inference/')\n",
        "import preprocessing\n",
        "import postprocessing\n",
        "import color_and_property_extractor\n",
        "import labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq2DNpXQ_0-n"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GO488S78_2GJ"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (1, h, w, 3)\n",
        "  \"\"\"\n",
        "  image = None\n",
        "  if(path.startswith('http')):\n",
        "    response = urlopen(path)\n",
        "    image_data = response.read()\n",
        "    image_data = BytesIO(image_data)\n",
        "    image = Image.open(image_data)\n",
        "  else:\n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "def load_model(model_handle):\n",
        "    \"\"\"Loads a TensorFlow SavedModel and returns a function that can be used to make predictions.\n",
        "\n",
        "    Args:\n",
        "      model_handle: A path to a TensorFlow SavedModel.\n",
        "\n",
        "    Returns:\n",
        "      A function that can be used to make predictions.\n",
        "    \"\"\"\n",
        "    print('loading model...')\n",
        "    print(model_handle)\n",
        "    model = tf.saved_model.load(model_handle)\n",
        "    print('model loaded!')\n",
        "    detection_fn = model.signatures['serving_default']\n",
        "    return detection_fn\n",
        "\n",
        "\n",
        "def perform_detection(model, image):\n",
        "  \"\"\"Performs Mask RCNN on an image using the specified model.\n",
        "\n",
        "  Args:\n",
        "    model: A function that can be used to make predictions.\n",
        "    image_np: A NumPy array representing the image to be detected.\n",
        "\n",
        "  Returns:\n",
        "    A list of detections.\n",
        "  \"\"\"\n",
        "  detection_fn = model(image)\n",
        "  detection_fn = {key: value.numpy() for key, value in detection_fn.items()}\n",
        "  return detection_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t7d00cJH-68Z"
      },
      "outputs": [],
      "source": [
        "# 'material_model' output is both material and its sub type e.g. Plastics_PET.\n",
        "# 'material_form_model' outputs the form of an object e.g. can, bottle, etc.\n",
        "MODEL_WEIGHTS_DICT = {\n",
        "  'MODELS_WEIGHTS_RESNET_V1' : {\n",
        "      'material_url': (\n",
        "          'https://storage.googleapis.com/tf_model_garden/vision/'\n",
        "          'waste_identification_ml/two_model_strategy/material_resnet_v1.zip'\n",
        "      ),\n",
        "      'material_form_url': (\n",
        "          'https://storage.googleapis.com/tf_model_garden/vision/'\n",
        "          'waste_identification_ml/two_model_strategy/material_form_resnet_v1.zip'\n",
        "      ),\n",
        "  },\n",
        "  'MODELS_WEIGHTS_RESNET_V2': {\n",
        "      'material_url': (\n",
        "          'https://storage.googleapis.com/tf_model_garden/vision/'\n",
        "          'waste_identification_ml/two_model_strategy/material_resnet_v2.zip'\n",
        "      ),\n",
        "      'material_form_url': (\n",
        "          'https://storage.googleapis.com/tf_model_garden/vision/'\n",
        "          'waste_identification_ml/two_model_strategy/material_form_resnet_v2.zip'\n",
        "      ),\n",
        "  },\n",
        "  'MODELS_WEIGHTS_MOBILENET_V2': {\n",
        "      'material_url': (\n",
        "          'https://storage.googleapis.com/tf_model_garden/vision/'\n",
        "          'waste_identification_ml/two_model_strategy/material_mobilenet_v2.zip'\n",
        "      ),\n",
        "      'material_form_url': (\n",
        "          'https://storage.googleapis.com/tf_model_garden/vision/'\n",
        "          'waste_identification_ml/two_model_strategy/material_form_mobilenet_v2.zip'\n",
        "      ),\n",
        "  }\n",
        "}\n",
        "\n",
        "MODELS_RESNET_V1 = {\n",
        "'material_model' : 'material/material_resnet_v1/saved_model/',\n",
        "'material_form_model' : 'material_form/material_form_resnet_v1/saved_model/',\n",
        "}\n",
        "\n",
        "MODELS_RESNET_V2 = {\n",
        "'material_model' : 'material/material_resnet_v2/saved_model/',\n",
        "'material_form_model' : 'material_form/material_form_resnet_v2/saved_model/',\n",
        "}\n",
        "\n",
        "MODELS_MOBILENET_V2 = {\n",
        "'material_model' : 'material/material_mobilenet_v2/saved_model/',\n",
        "'material_form_model' : 'material_form/material_form_mobilenet_v2/saved_model/',\n",
        "}\n",
        "\n",
        "LABELS = {\n",
        "    'material_model': (\n",
        "        'models/official/projects/waste_identification_ml/pre_processing/'\n",
        "        'config/data/two_model_strategy_material.csv'\n",
        "    ),\n",
        "    'material_form_model': (\n",
        "        'models/official/projects/waste_identification_ml/pre_processing/'\n",
        "        'config/data/two_model_strategy_material_form.csv'\n",
        "    ),\n",
        "}\n",
        "\n",
        "# Path to a sample image stored in the repo.\n",
        "IMAGES_FOR_TEST = {\n",
        "    'Image1': (\n",
        "        'models/official/projects/waste_identification_ml/pre_processing/'\n",
        "        'config/sample_images/image_2.png'\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XjfDEq--UlE"
      },
      "source": [
        "## Import pre-trained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZQ435YHN3Lr-"
      },
      "outputs": [],
      "source": [
        "selected_model = \"MODELS_WEIGHTS_RESNET_V2\" #@param [\"MODELS_WEIGHTS_RESNET_V1\", \"MODELS_WEIGHTS_RESNET_V2\", \"MODELS_WEIGHTS_MOBILENET_V2\"]\n",
        "\n",
        "if selected_model == \"MODELS_WEIGHTS_RESNET_V1\":\n",
        "  ALL_MODELS = MODELS_RESNET_V1\n",
        "elif selected_model == \"MODELS_WEIGHTS_RESNET_V2\":\n",
        "  ALL_MODELS = MODELS_RESNET_V2\n",
        "elif selected_model == \"MODELS_WEIGHTS_MOBILENET_V2\":\n",
        "  ALL_MODELS = MODELS_MOBILENET_V2\n",
        "\n",
        "# Extract URLs based on the selected model\n",
        "url1 = MODEL_WEIGHTS_DICT[selected_model]['material_url']\n",
        "url2 = MODEL_WEIGHTS_DICT[selected_model]['material_form_url']\n",
        "\n",
        "# Download and unzip the selected model weights\n",
        "!python3 download_and_unzip_models.py $url1 $url2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6mmyLsOJicF"
      },
      "source": [
        "## Load label map data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5RUzrh0uegqt"
      },
      "outputs": [],
      "source": [
        "# The total number of predicted labels (category_indices) for a combined model = 741.\n",
        "category_indices, category_index = labels.load_labels(LABELS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFczkMGBClZ4"
      },
      "source": [
        "## Load pre-trained weights for both models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J6MgjOSC5JO",
        "outputId": "b1bc0de9-dccd-4afc-af25-6cc238128581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model...\n",
            "material/material_resnet_v2/saved_model/\n",
            "model loaded!\n",
            "loading model...\n",
            "material_form/material_form_resnet_v2/saved_model/\n",
            "model loaded!\n"
          ]
        }
      ],
      "source": [
        "# Loading both models.\n",
        "detection_fns = [load_model(model_path) for model_path in ALL_MODELS.values()]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inference Utilities**"
      ],
      "metadata": {
        "id": "iC5MpuaqcP7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(image_path, is_display):\n",
        "  image_np = load_image_into_numpy_array(str(image_path))\n",
        "\n",
        "  # print('min:', np.min(image_np[0]), 'max:', np.max(image_np[0]))\n",
        "\n",
        "  print('image is loaded\\n')\n",
        "  if is_display:\n",
        "    plt.figure(figsize=(24,32))\n",
        "    plt.imshow(image_np[0])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  return image_np\n",
        "\n",
        "\n",
        "def pre_processing(image_np, is_display):\n",
        "  height = detection_fns[0].structured_input_signature[1]['inputs'].shape[1]\n",
        "  width = detection_fns[0].structured_input_signature[1]['inputs'].shape[2]\n",
        "  input_size = (height, width)\n",
        "  print(f'input size is {height}x{width}')\n",
        "\n",
        "  image_np_cp = tf.image.resize(image_np[0], input_size, method=tf.image.ResizeMethod.AREA)\n",
        "  image_np_cp = tf.cast(image_np_cp, tf.uint8)\n",
        "  image_np = preprocessing.normalize_image(image_np_cp)\n",
        "  image_np = tf.expand_dims(image_np, axis=0)\n",
        "  image_np.get_shape()\n",
        "\n",
        "  print('pre processing done\\n')\n",
        "\n",
        "  if is_display:\n",
        "    plt.figure(figsize=(24,32))\n",
        "    plt.imshow(image_np[0])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  return image_np, image_np_cp, height, width\n",
        "\n",
        "\n",
        "def display_final_result(final_result, image_np_cp):\n",
        "  %matplotlib inline\n",
        "  image_new = image_np_cp.numpy().copy()\n",
        "\n",
        "  if 'detection_masks_reframed' in final_result:\n",
        "    final_result['detection_masks_reframed'] = final_result['detection_masks_reframed'].astype(np.uint8)\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_new,\n",
        "        final_result['detection_boxes'][0],\n",
        "        (final_result['detection_classes'] + 0).astype(int),\n",
        "        final_result['detection_scores'][0],\n",
        "        category_index=category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=100,\n",
        "        min_score_thresh=0.6,\n",
        "        agnostic_mode=False,\n",
        "        instance_masks=final_result.get('detection_masks_reframed', None),\n",
        "        line_thickness=2)\n",
        "\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.imshow(image_new)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def get_detection_info(final_result):\n",
        "    num_objects = int(final_result['num_detections'][0])\n",
        "    object_types = final_result['detection_classes_names']\n",
        "    detection_boxes = final_result['detection_boxes'][0]\n",
        "\n",
        "    coordinates = []\n",
        "    for box in detection_boxes:\n",
        "        ymin, xmin, ymax, xmax = box\n",
        "        x_center = (xmin + xmax) / 2\n",
        "        y_center = (ymin + ymax) / 2\n",
        "        coordinates.append((x_center, y_center))\n",
        "\n",
        "    return num_objects, object_types, coordinates\n",
        "\n",
        "\n",
        "def inference(path_image, is_display):\n",
        "  image_np, image_np_cp, height, width = pre_processing(load_img(path_image, is_display), is_display)\n",
        "\n",
        "  print('performing inference')\n",
        "  results = list(map(lambda model: perform_detection(model, image_np), detection_fns))\n",
        "  print('inference done\\n')\n",
        "\n",
        "  # from here, from one cell.\n",
        "  use_generic_color = True\n",
        "\n",
        "\n",
        "  SCORE_THRESH = 0.8\n",
        "\n",
        "  no_detections_in_first = results[0]['num_detections'][0]\n",
        "  no_detections_in_second = results[1]['num_detections'][0]\n",
        "\n",
        "  if no_detections_in_first !=0 and no_detections_in_second != 0:\n",
        "    results = [postprocessing.reframing_masks(detection, height, width) for detection in results]\n",
        "\n",
        "    max_detection = max(no_detections_in_first, no_detections_in_second)\n",
        "\n",
        "    area_threshold = 0.3 * np.prod(image_np_cp.shape[:2])\n",
        "\n",
        "    final_result = postprocessing.find_similar_masks(\n",
        "        results[0],\n",
        "        results[1],\n",
        "        max_detection,\n",
        "        SCORE_THRESH,\n",
        "        category_indices,\n",
        "        category_index,\n",
        "        area_threshold\n",
        "    )\n",
        "\n",
        "    transformed_boxes = []\n",
        "    for bb in final_result['detection_boxes'][0]:\n",
        "        YMIN = int(bb[0]*height)\n",
        "        XMIN = int(bb[1]*width)\n",
        "        YMAX = int(bb[2]*height)\n",
        "        XMAX = int(bb[3]*width)\n",
        "        transformed_boxes.append([YMIN, XMIN, YMAX, XMAX])\n",
        "\n",
        "    filtered_boxes, index_to_delete = (\n",
        "      postprocessing.filter_bounding_boxes(transformed_boxes))\n",
        "\n",
        "    final_result['num_detections'][0] -= len(index_to_delete)\n",
        "    final_result['detection_classes'] = np.delete(\n",
        "        final_result['detection_classes'], index_to_delete)\n",
        "    final_result['detection_scores'] = np.delete(\n",
        "        final_result['detection_scores'], index_to_delete, axis=1)\n",
        "    final_result['detection_boxes'] = np.delete(\n",
        "        final_result['detection_boxes'], index_to_delete, axis=1)\n",
        "    final_result['detection_classes_names'] = np.delete(\n",
        "        final_result['detection_classes_names'], index_to_delete)\n",
        "    final_result['detection_masks_reframed'] = np.delete(\n",
        "        final_result['detection_masks_reframed'], index_to_delete, axis=0)\n",
        "\n",
        "    if final_result['num_detections'][0]:\n",
        "\n",
        "      dfs, cropped_masks = (\n",
        "          color_and_property_extractor.extract_properties_and_object_masks(\n",
        "              final_result, height, width, image_np_cp))\n",
        "      features = pd.concat(dfs, ignore_index=True)\n",
        "      features['image_name'] = 'Image 1' #TODO: figure out what to do here.\n",
        "      features.rename(columns={\n",
        "          'centroid-0':'y',\n",
        "          'centroid-1':'x',\n",
        "          'bbox-0':'bbox_0',\n",
        "          'bbox-1':'bbox_1',\n",
        "          'bbox-2':'bbox_2',\n",
        "          'bbox-3':'bbox_3'\n",
        "      }, inplace=True)\n",
        "\n",
        "\n",
        "  features.iloc[0]\n",
        "\n",
        "  if is_display:\n",
        "    display_final_result(final_result, image_np_cp)\n",
        "\n",
        "  return final_result, features, image_np_cp"
      ],
      "metadata": {
        "id": "wyT1yh2LRghu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Colab Codes**"
      ],
      "metadata": {
        "id": "3l8dESZvmrRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive/plugins/')\n",
        "import gs_manager_colab as gs_manager"
      ],
      "metadata": {
        "id": "-ar7cKa7pLq9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_manager.initialize.init(\"DetectedOutput\", \"Sheet1\")"
      ],
      "metadata": {
        "id": "r-nZAzmpmuqF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deployment Code**"
      ],
      "metadata": {
        "id": "JRvtVoyHcr5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "nUDxpJCccxk9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "C5yVRSXpH-7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82945ea9-aa47-49c5-fdce-b79cca45d975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "checking...\n",
            "Changes detected:\n",
            "Added file: frame_2cz1x5t3.jpg\n",
            "\n",
            "starting resolving\n",
            "image is loaded\n",
            "\n",
            "input size is 512x1024\n",
            "pre processing done\n",
            "\n",
            "performing inference\n",
            "inference done\n",
            "\n",
            "resolving done\n",
            "\n",
            "data uploading\n",
            "current cell time is 20240808190439\n",
            "datecell, tokenCell, dataCell is correctly oriented\n",
            "data uploading complete.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "PATH_bucket = \"/content/drive/MyDrive/data_bucket/img_bucket\"\n",
        "\n",
        "\n",
        "def check_folder_changes(folder_path):\n",
        "  keep_checking = True #@param {type:\"boolean\"}\n",
        "  initial_files = set(file for file in os.listdir(folder_path))\n",
        "\n",
        "  if keep_checking:\n",
        "    print('checking...')\n",
        "    time.sleep(1)\n",
        "\n",
        "    current_files = set(file for file in os.listdir(folder_path))\n",
        "\n",
        "    added_files = current_files - initial_files\n",
        "    removed_files = initial_files - current_files\n",
        "\n",
        "    if added_files or removed_files:\n",
        "        print(\"Changes detected:\")\n",
        "        if added_files:\n",
        "            for added_file in added_files:\n",
        "                print(\"Added file:\", added_file)\n",
        "                PATH_target_pic = os.path.join(folder_path, added_file)\n",
        "\n",
        "                print('\\nstarting resolving')\n",
        "                final_result, features, image_np_cp = inference(PATH_target_pic, False)\n",
        "                print('resolving done\\n')\n",
        "\n",
        "                print('data uploading')\n",
        "                sliced, k = gs_manager.main.data_manager(final_result)\n",
        "\n",
        "                added_file = added_file.replace('.jpg', '')\n",
        "\n",
        "                for i in range(k):\n",
        "                  gs_manager.main.gs_edit(gs_manager.bucket.worksheet, f'{added_file}', str(sliced[i]))\n",
        "\n",
        "                print('data uploading complete.\\n')\n",
        "\n",
        "        if removed_files:\n",
        "            print(\"Removed files:\", removed_files)\n",
        "\n",
        "\n",
        "        initial_files = current_files\n",
        "    else:\n",
        "      check_folder_changes(folder_path)\n",
        "\n",
        "check_folder_changes(PATH_bucket)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}